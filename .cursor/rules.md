## Правила использования MCP в Cursor (авто-маршрутизация)

Эти правила настраивают поведение ассистента в Cursor для автоматического выбора и вызова MCP‑серверов по намерению пользователя, без дополнительных указаний. Ответы всегда на русском.

### Основные принципы
- Ответ по умолчанию: на русском, коротко и по делу; при необходимости — структурировано.
- Автоприменение MCP: ассистент сам выбирает нужный MCP‑инструмент по задаче.
- Приоритет контекстов: локальный код → библиотечная документация (Context7) → веб‑поиск/краулинг (Firecrawl / WebSearch).
- Параллелизация: независимые чтения/поиски запускаются параллельно.
- Неинтерактивность: команды и вызовы должны быть без запроса ввода, использовать флаги non‑interactive.
- Приватность: не отправлять секреты и приватные файлы наружу.

### Маршрутизация по задачам
- Документация/справка по библиотеке, API, примерам кода, версиям:
  1) Context7: resolve library ID → fetch docs по нужной теме.
  2) При нескольких библиотеках: собрать по каждой краткие выдержки, сравнить.
- Сравнения библиотек и выбор инструмента: Context7 для официальных доков; при необходимости дополнить свежими источниками через веб‑поиск.
- Актуальные новости/изменения, «что нового», «best practices сейчас»: Firecrawl Search (по умолчанию) или WebSearch; при известном URL — Firecrawl Scrape.
- Извлечение структурированных данных с веб‑страниц (цены/таблицы/поля): Firecrawl Extract с явной схемой.
- Масштабные разделы сайта/документации: Firecrawl Map → при необходимости Firecrawl Crawl (ограничить глубину/лимиты).
- Глубокое исследование темы: Firecrawl Deep Research (строгие лимиты времени/количества URL).
- Известный URL и нужен контент страницы: Firecrawl Scrape (onlyMainContent=true; maxAge использовать, если допустимо).
- Работа с кодовой базой (как устроено, где реализовано, зачем работает так): semantic поиск по коду в первую очередь; для точных совпадений — точечный grep.
- Создание/изменение файлов проекта: вносить правки напрямую; после правок — проверить линтеры/сборку, исправить ошибки.

### Конкретные триггеры
- «Как использовать/пример/методы/параметры X?», «API X», «возможности X» → Context7: resolve → get docs (topic по ключевым словам запроса). Если X неоднозначно — уточнить либо выбрать ближайшее совпадение с заметкой.
- «Сравни X и Y», «что выбрать для …» → Context7 по X и Y; при необходимости дополнить веб‑поиском свежих сравнений/бенчмарков.
- «Найди последние изменения/релизы/новости …» → Firecrawl Search (news/временные фильтры), при точном источнике — Scrape.
- «Спарси эти страницы/извлеки таблицу/цены» → Firecrawl Extract с аккуратной схемой; иначе Scrape.
- «Покрой раздел сайта/дока полностью» → Map → (опционально) Crawl с maxDepth≤2–3 и limit разумным.
- «Проанализируй тему глубоко» → Deep Research c timeLimit и maxUrls.
- «Где в коде …?», «как работает … внутри?» → semantic поиск; затем целевой просмотр файлов; точные символы — grep.

### Параметры вызовов (по умолчанию)
- Context7
  - Всегда сначала: resolve‑library‑id (точное соответствие имени; если неоднозначно — выбрать лучший матч, сообщить об этом кратко).
  - Затем: get‑library‑docs с topic, релевантным запросу. tokens подбирать под объём ответа; избегать чрезмерных объёмов.
- Firecrawl Search
  - limit: 5–8; lang: ru или en по контенту; country: us/ru по задаче; onlyMainContent=true.
  - Для «свежих» тем: использовать временные фильтры.
- Firecrawl Scrape
  - onlyMainContent=true; waitFor при SPA; maxAge использовать для кеша.
- Firecrawl Map/Crawl
  - maxDepth=2–3; limit консервативный (≤50), deduplicateSimilarURLs=true.
- Firecrawl Extract
  - Задавать понятную JSON‑схему; запрещать внешние ссылки, если не нужны.
- WebSearch
  - Использовать, если Firecrawl недоступен или требуется иной источник; возвращать ссылки.
- Команды/процессы
  - Для длинных/постоянных процессов — запускать в фоне. Добавлять | cat к пагинаторам.

### Гигиена выполнения
- Не раскрывать ключи/токены, приватные файлы, большие бинарные блоки.
- Для больших ответов — структурировать; цитаты сводить к минимуму, давать ссылки.
- По коду: после правок проверять линтеры на изменённых файлах и исправлять явные ошибки.

### Предпочтения
- «use context7»: для любых вопросов о библиотеках/фреймворках/их API по умолчанию использовать Context7; веб‑источники подключать только для актуальных новостей/кейсов вне доков.

### Мини‑процедуры
- Библиотека/фреймворк
  1) Context7 resolve‑id (по точному названию).
  2) Context7 get‑docs (topic из запроса; при необходимости несколько тем последовательно).
  3) Свести ответ: кратко + ссылки на разделы доков.
- Веб‑инфо неизвестного источника
  1) Firecrawl Search (5–8 результатов) параллельно по разным формулировкам.
  2) При известном URL — Scrape; если много страниц — Map/Crawl.
  3) Для структурированных полей — Extract со схемой.
- Кодовая база
  1) Семантический поиск «как/где/что» по коду.
  2) При больших файлах — таргетированный поиск по сигнатурам.
  3) Приводить цитаты кода точечно с ссылками на строки.


